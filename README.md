# ppo-reproduce
Reproduce the PPO algorithm from the paper 《Proximal Policy Optimization Algorithms》


## Original Project
- This project is a reproduce of this repo: [PPO-PyTorch](https://github.com/nikhilbarhate99/PPO-PyTorch.git)
  



## Introduction






## Usage
- To train a new network : run `train.py`
- To test a preTrained network : run `test.py`
- To plot graphs using log files : run `plot_graph.py`
- To save images for gif and make gif using a preTrained network : run `make_gif.py`
- All parameters and hyperparamters to control training / testing / graphs / gifs are in their respective `.py` file
- All the hyperparameters used for training (preTrained) policies are listed in the README.md in `ppo_pretrained` directory







## Citing
```bibtex
@misc{pytorch_minimal_ppo,
    author = {Barhate, Nikhil},
    title = {Minimal PyTorch Implementation of Proximal Policy Optimization},
    year = {2021},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/nikhilbarhate99/PPO-PyTorch}},
}
```
